{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026e70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9037f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairTrader:\n",
    "    def __init__(self, start_date, end_date, period, cutoffs, lookback1, lookback2, lookback3, z_score_cutoff, days_before_end, deg_freedom, tickers):\n",
    "        self.data = self.data_download(start_date, end_date, tickers)\n",
    "        self.period = period  # Trading period length in months\n",
    "        self.cutoffs = cutoffs  # Dates to split training/testing data\n",
    "        self.lookback1 = lookback1  # Window size for calculating rolling stats\n",
    "        self.lookback2 = lookback2  # Window size for z-score calculation\n",
    "        self.lookback3 = lookback3  # Window size for regression\n",
    "        self.z_score_cutoff = z_score_cutoff  # Threshold for trading signals\n",
    "        self.days_before_end = days_before_end  # Stop trading X days before period end\n",
    "        self.deg_freedom = deg_freedom  # Adjustment factor for trade exit thresholds\n",
    "        \n",
    "    def data_download(self, start_date, end_date, tickers):\n",
    "        # Downloads historical price data from Yahoo Finance\n",
    "        # Filters out stocks with insufficient data points\n",
    "        historical_prices = pd.DataFrame()\n",
    "\n",
    "        for tickr in tickers:\n",
    "            data = yf.download(tickr, start=start_date, end=end_date)\n",
    "            data = data.dropna(how='all')\n",
    "            \n",
    "            if data.shape[0] < 5282:  # Skip tickers with insufficient data\n",
    "                continue\n",
    "            else:\n",
    "                if historical_prices.empty:\n",
    "                    historical_prices.index = data.index\n",
    "                historical_prices[str(tickr)] = data['Adj Close']\n",
    "        return historical_prices\n",
    "        \n",
    "    def prepare_train_test(self, cutoff):\n",
    "        # Splits data into training and testing sets based on cutoff date\n",
    "        train_date = (cutoff - pd.DateOffset(years=self.lookback3)).replace(day=1)\n",
    "        end = (cutoff + pd.DateOffset(months=self.period)).replace(day=1)\n",
    "        train_data = self.data[self.data.index < cutoff]\n",
    "        test_data = self.data[self.data.index >= cutoff]\n",
    "        test_data = test_data.loc[:end]\n",
    "        \n",
    "        return train_data, test_data, train_date, end\n",
    "    \n",
    "    def ratios(self, p1, p2, all_data):\n",
    "        # Calculates rolling hedge ratios between pairs using OLS regression\n",
    "        lookback = self.lookback3 * 251\n",
    "        model = RollingOLS(np.log2(all_data[p2]), np.log2(all_data[p1]), window=lookback)\n",
    "        regres = model.fit()\n",
    "        return regres.params\n",
    "    \n",
    "    def find_corr_pairs(self, data):\n",
    "        # Identifies pairs with high correlation (>= 0.9)\n",
    "        num_columns = data.shape[1]\n",
    "        cor_matrix = np.zeros((num_columns, num_columns))\n",
    "        keys = data.keys()\n",
    "        pairs = []\n",
    "\n",
    "        for i in range(num_columns):\n",
    "            for j in range(i + 1, num_columns):\n",
    "                cor_matrix[i, j] = data[keys[i]].corr(data[keys[j]], method='pearson')\n",
    "                cor_matrix[j, i] = cor_matrix[i, j]\n",
    "\n",
    "                if abs(cor_matrix[i, j]) >= 0.9:\n",
    "                    pairs.append((keys[i], keys[j]))\n",
    "\n",
    "        return cor_matrix, pairs\n",
    "\n",
    "    def find_coint_pairs(self, data, corr_pairs):\n",
    "        # Tests for cointegration among correlated pairs\n",
    "        pairs = []\n",
    "        for i in range(len(corr_pairs)):\n",
    "            result = coint(data[corr_pairs[i,0]], data[corr_pairs[i,1]])\n",
    "            if result[1] <= 0.05:  # Using 5% significance level\n",
    "                pairs.append((corr_pairs[i,0], corr_pairs[i,1]))\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def get_pairs(self, train_data, train_date, cutoff):\n",
    "        # Combines correlation, cointegration, and ADF tests to identify tradeable pairs\n",
    "        train_data_scaled = (train_data-train_data.min())/(train_data.max()-train_data.min())\n",
    "        split_date = cutoff\n",
    "        corr_data = train_data.loc[train_date:split_date].corr(method='pearson')\n",
    "        pvalue_matrix, correlated_pairs = self.find_corr_pairs(corr_data)\n",
    "        correlated_pairs = np.array(correlated_pairs)\n",
    "        pairs = self.find_coint_pairs(train_data_scaled[train_date:split_date], correlated_pairs)\n",
    "        \n",
    "        # Convert pairs to array format and prepare for signal generation\n",
    "        pairs_arr = np.empty((len(pairs),2), dtype=object)\n",
    "        for i in range(len(pairs)):\n",
    "            pair = pairs[i]\n",
    "            pair = list(pair)\n",
    "            pairs_arr[i,0] = pair[0]\n",
    "            pairs_arr[i,1] = pair[1]\n",
    "        \n",
    "        # Create sandbox for testing pairs\n",
    "        sandbox = pd.DataFrame()\n",
    "        for i in range(len(pairs_arr)):\n",
    "            p1 = f\"{chr(65 + i)}1\" \n",
    "            p2 = f\"{chr(65 + i)}2\"\n",
    "            sandbox[p1] = train_data[pairs_arr[i,0]]\n",
    "            sandbox[p2] = train_data[pairs_arr[i,1]]   \n",
    "\n",
    "        # Calculate rolling regression parameters\n",
    "        model_params = pd.DataFrame()\n",
    "        fit_date = pd.to_datetime(train_date, format='%m/%d/%Y')\n",
    "        fit_date = (fit_date - pd.DateOffset(years=self.lookback3)).replace(day=1)\n",
    "\n",
    "        # Perform ADF test on spreads to confirm mean reversion\n",
    "        for i in range(len(pairs_arr)):\n",
    "            lookback = self.lookback1*251\n",
    "            p1 = f\"{chr(65 + i)}1\" \n",
    "            p2 = f\"{chr(65 + i)}2\"\n",
    "            model = RollingOLS(np.log2(sandbox[p2].loc[fit_date:split_date]), \n",
    "                             np.log2(sandbox[p1].loc[fit_date:split_date]), \n",
    "                             window=lookback)\n",
    "            regres = model.fit()\n",
    "            model_params[i] = regres.params\n",
    "\n",
    "        spread = np.empty(len(pairs_arr), dtype=object)\n",
    "        for i in range(len(pairs_arr)):\n",
    "            p1 = f\"{chr(65 + i)}1\" \n",
    "            p2 = f\"{chr(65 + i)}2\"\n",
    "            spread[i] = sandbox[p2] - sandbox[p1]*model_params[i]\n",
    "\n",
    "        # Filter pairs based on ADF test results\n",
    "        new_pairs = []\n",
    "        for i in range(len(pairs_arr)):\n",
    "            adf = adfuller(spread[i].loc[train_date:split_date], maxlag=0)\n",
    "            if(adf[0] <= (-3.4355588184378574)):  # Critical value for ADF test\n",
    "                new_pairs.append(i)\n",
    "                \n",
    "        copy_arr = np.zeros((len(new_pairs),2), dtype=object)\n",
    "        for i in range(len(new_pairs)):\n",
    "            copy_arr[i] = pairs_arr[new_pairs[i]]\n",
    "\n",
    "        pairs_arr = copy_arr.copy()   \n",
    "        return pairs_arr, sandbox\n",
    "\n",
    "    def generate_signals(self, test_data, pairs_arr, sandbox):\n",
    "        # Generates trading signals based on z-scores and position management rules\n",
    "        signals = pd.DataFrame()\n",
    "        model_params = pd.DataFrame()\n",
    "\n",
    "        # Initialize signals dataframe with test data\n",
    "        for i in range(len(pairs_arr)):\n",
    "            p1 = f\"{chr(65 + i)}1\" \n",
    "            p2 = f\"{chr(65 + i)}2\"\n",
    "            signals[p1] = test_data[pairs_arr[i,0]]\n",
    "            signals[p2] = test_data[pairs_arr[i,1]]\n",
    "\n",
    "        all_data = pd.concat([sandbox, signals])\n",
    "\n",
    "        # Calculate signals for each pair\n",
    "        for i in range(len(pairs_arr)):\n",
    "            p1 = f\"{chr(65 + i)}1\" \n",
    "            p2 = f\"{chr(65 + i)}2\"\n",
    "            z_name = f\"z{chr(65 + i)}\"\n",
    "            letter = chr(65 + i)\n",
    "\n",
    "            # Calculate hedge ratios and spreads\n",
    "            model_params[letter] = self.ratios(p1, p2, all_data).dropna()\n",
    "            spread = ((np.log2(signals[p1])*model_params[letter])-np.log2(signals[p2])).dropna()\n",
    "            \n",
    "            # Calculate z-scores and trading bands\n",
    "            signals[z_name], mean, std = self.zscore(spread, sandbox, model_params, p1, p2, letter)\n",
    "            upper = mean + self.z_score_cutoff*std\n",
    "            lower = mean - self.z_score_cutoff*std\n",
    "            \n",
    "            signals[f'z{letter} Upper Limit'] = upper\n",
    "            signals[f'z{letter} Lower Limit'] = lower\n",
    "\n",
    "            # Generate trading signals based on z-score thresholds\n",
    "            signals[f'{p1}S'] = np.select([signals[z_name] > signals[f'z{letter} Upper Limit'],\n",
    "                                         signals[z_name] < signals[f'z{letter} Lower Limit']],\n",
    "                                        [-1, 1], default=0)\n",
    "\n",
    "            # Apply position management rules\n",
    "            for z in range(len(signals)-1):\n",
    "                up_cutoff = upper.iloc[z]-self.deg_freedom*(upper.iloc[z]-lower.iloc[z])/2\n",
    "                low_cutoff = lower.iloc[z]+self.deg_freedom*(upper.iloc[z]-lower.iloc[z])/2\n",
    "\n",
    "                # Hold positions until exit threshold is reached\n",
    "                if(signals[f'{p1}S'].iloc[z]==1):\n",
    "                    if(signals[z_name].iloc[z+1]<= low_cutoff):\n",
    "                        signals.at[signals.index[z+1], f'{p1}S'] =signals[f'{p1}S'].iloc[z]    \n",
    "                elif(signals[f'{p1}S'].iloc[z]==-1):\n",
    "                    if(signals[z_name].iloc[z+1]>= up_cutoff):\n",
    "                        signals.at[signals.index[z+1], f'{p1}S']=signals[f'{p1}S'].iloc[z]\n",
    "\n",
    "            # Calculate opposite positions for pair trading\n",
    "            signals[f'{p2}S'] = -signals[f'{p1}S']\n",
    "            signals[f'{letter} positions1'] = signals[f'{p1}S'].diff()\n",
    "            signals[f'{letter} positions2'] = signals[f'{p2}S'].diff()\n",
    "            \n",
    "            # Set initial positions\n",
    "            signals.at[signals.index[0], f'{letter} positions2'] = signals[f'{p2}S'].iloc[0]\n",
    "            signals.at[signals.index[0], f'{letter} positions1'] = signals[f'{p1}S'].iloc[0]\n",
    "\n",
    "            # Close positions before period end\n",
    "            no_trade = self.days_before_end\n",
    "            zero_idx = signals[f'{p1}S'].iloc[-no_trade:].eq(0).idxmax()\n",
    "            if pd.notna(zero_idx):\n",
    "                if signals[f'{p1}S'].loc[zero_idx] == 0:\n",
    "                    signals[f'{p1}S'].loc[zero_idx:] = 0\n",
    "                    signals[f'{p2}S'].loc[zero_idx:] = 0\n",
    "        \n",
    "        signals = signals.dropna()\n",
    "        return signals, model_params\n",
    "    \n",
    "    def zscore(self, series, sandbox, model_params, p1, p2, letter):\n",
    "        # Calculates z-scores for spread series using rolling windows\n",
    "        lookback1 = self.lookback1*251\n",
    "        lookback2 = self.lookback2*251\n",
    "        train_ratios = ((np.log2(sandbox[p1])*model_params[letter])-(np.log2(sandbox[p2]))).dropna()\n",
    "\n",
    "        data = pd.concat([train_ratios, series])\n",
    "        \n",
    "        # Calculate rolling statistics\n",
    "        rolling_mean = data.rolling(window=lookback1, center=False).mean().dropna(how='all')\n",
    "        rolling_std = data.rolling(window=lookback1, center=False).std().dropna(how='all')\n",
    "        z_score = ((data - rolling_mean)/rolling_std).dropna(how='all')\n",
    "\n",
    "        # Calculate z-score bands\n",
    "        mean = z_score.rolling(window=lookback2, center=False).mean().dropna(how='all')\n",
    "        std = z_score.rolling(window=lookback2, center=False).std().dropna(how='all')\n",
    "\n",
    "        # Align series with test period\n",
    "        z_score = z_score.loc[series.index[0]:]\n",
    "        mean = mean.loc[series.index[0]:]\n",
    "        std = std.loc[series.index[0]:]\n",
    "\n",
    "        return z_score, mean, std\n",
    "     \n",
    "        \n",
    "    def calc_cagr(self, cutoff, signals, pairs_arr, model_params, end):\n",
    "        # Calculates Compound Annual Growth Rate and portfolio performance\n",
    "        portfolio = pd.DataFrame()\n",
    "        results1 = []  # Store CAGR values\n",
    "        results2 = []  # Store final portfolio values\n",
    "        \n",
    "        # Initialize portfolio with signal data for each pair\n",
    "        for i in range(len(pairs_arr)):\n",
    "            p1 = f\"{chr(65 + i)}1\"\n",
    "            p2 = f\"{chr(65 + i)}2\"\n",
    "            z_name = f\"z{chr(65 + i)}\"\n",
    "            letter = chr(65 + i)\n",
    "\n",
    "            portfolio[p1] = signals[p1]\n",
    "            portfolio[p2] = signals[p2]\n",
    "            portfolio[z_name] = signals[z_name]\n",
    "            portfolio[f'z Upper Limit{letter}'] = signals[f'z{letter} Upper Limit']\n",
    "            portfolio[f'z Lower Limit{letter}'] = signals[f'z{letter} Lower Limit']\n",
    "\n",
    "            # Calculate percentage changes for returns\n",
    "            pc1 = portfolio[p1].pct_change().dropna()\n",
    "            pc2 = portfolio[p2].pct_change().dropna()\n",
    "\n",
    "        # Set initial portfolio value\n",
    "        initial_capital = 100000\n",
    "        portfolio['Capital'] = initial_capital    \n",
    "\n",
    "        # Calculate daily portfolio values based on positions and returns\n",
    "        for z in range(len(portfolio)-1):\n",
    "            total_z = 0\n",
    "            tickers = []\n",
    "            \n",
    "            # Find active positions for current day\n",
    "            for i in range(len(pairs_arr)):\n",
    "                p1 = f\"{chr(65 + i)}1\"\n",
    "                p2 = f\"{chr(65 + i)}2\"\n",
    "                z_name = f\"z{chr(65 + i)}\"\n",
    "                letter = chr(65 + i)\n",
    "\n",
    "                if(signals[f'{p1}S'].iloc[z]!=0):        \n",
    "                    tickers.append(letter)\n",
    "\n",
    "            # If no active positions, capital remains unchanged\n",
    "            if (len(tickers)==0):\n",
    "                portfolio['Capital'].iloc[z+1] = portfolio['Capital'].iloc[z]\n",
    "\n",
    "            else:\n",
    "                capital = 0\n",
    "                # Calculate returns for each active pair\n",
    "                for letter in tickers:\n",
    "                    p1 = f\"{letter}1\"\n",
    "                    p2 = f\"{letter}2\"\n",
    "                    # Divide capital equally among active pairs\n",
    "                    multiplier = 1/len(tickers)\n",
    "                    date = signals.index[z]\n",
    "\n",
    "                    # Apply position sizing based on hedge ratio\n",
    "                    if(model_params[letter].loc[date]<1):                \n",
    "                        capital += (.5*multiplier)*(portfolio[f'Capital'].iloc[z]*signals[f'{p1}S'].iloc[z]*pc1.iloc[z]*model_params[letter].loc[date])\n",
    "                        capital += (.5*multiplier)*(portfolio[f'Capital'].iloc[z]*signals[f'{p2}S'].iloc[z]*pc2.iloc[z])\n",
    "                    elif(model_params[letter].loc[date]>=1):\n",
    "                        capital += (.5*multiplier)*(portfolio[f'Capital'].iloc[z]*signals[f'{p1}S'].iloc[z]*pc1.iloc[z])\n",
    "                        capital += (.5*multiplier)*(portfolio[f'Capital'].iloc[z]*signals[f'{p2}S'].iloc[z]*pc2.iloc[z]/model_params[letter].loc[date])\n",
    "                \n",
    "                # Update portfolio value for next day\n",
    "                capital += portfolio[f'Capital'].iloc[z]\n",
    "                portfolio[f'Capital'].iloc[z+1] = capital\n",
    "\n",
    "        portfolio = portfolio.dropna()\n",
    "        print(f'Dates {cutoff} : {end}')\n",
    "        \n",
    "        # Calculate CAGR if portfolio has data\n",
    "        if(len(portfolio)>0):\n",
    "            final_portfolio = portfolio['Capital'].iloc[-1]\n",
    "            # Calculate number of days in trading period\n",
    "            delta = (portfolio.index[-1] - portfolio.index[0]).days\n",
    "            YEAR_DAYS = 365\n",
    "            # Calculate annualized return\n",
    "            returns = (final_portfolio/(initial_capital)) ** (YEAR_DAYS/delta) - 1\n",
    "            results1.append(returns*100)  # Convert to percentage\n",
    "            results2.append(final_portfolio)\n",
    "        else:\n",
    "            # If no trades were made, return 0% CAGR and initial capital\n",
    "            results1.append(0)\n",
    "            results2.append(initial_capital)\n",
    "            \n",
    "        return results1, results2, portfolio\n",
    "def run(start_date, end_date, cutoffs, period, lookback1, lookback2, lookback3, z_score_cutoff, days_before_end, deg_freedom, tickers):\n",
    "    # Main function to execute the pair trading strategy\n",
    "    trader = PairTrader(start_date, end_date, period, cutoffs, lookback1, lookback2, lookback3, z_score_cutoff, days_before_end, deg_freedom, tickers)\n",
    "    \n",
    "    results1 = []  # Store CAGR results\n",
    "    results2 = []  # Store final portfolio values\n",
    "    \n",
    "    # Run strategy for each cutoff date\n",
    "    for cutoff in cutoffs:\n",
    "        print(f\"Running strategy for cutoff: {cutoff}\")\n",
    "        train_data, test_data, train_date, end = trader.prepare_train_test(cutoff)\n",
    "        pairs_arr, sandbox = trader.get_pairs(train_data, train_date, cutoff)\n",
    "        signals, model_params = trader.generate_signals(test_data, pairs_arr, sandbox)\n",
    "        result1, result2, portfolio = trader.calc_cagr(cutoff, signals, pairs_arr, model_params, end)\n",
    "        \n",
    "        results1.extend(result1)\n",
    "        results2.extend(result2)\n",
    "\n",
    "    # Print results for each period\n",
    "    print(\"All results:\")\n",
    "    for cutoff, cagr, final_value in zip(cutoffs, results1, results2):\n",
    "        print(f\"Cutoff: {cutoff}, CAGR: {cagr:.3f}%, Final Portfolio Value: {final_value:.2f}\")\n",
    "    return results1, results2, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0ffb86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['APA', 'BKR', 'COP', 'CTRA', 'CVX', 'DVN', 'EOG', 'EQT', \n",
    "         'FANG', 'HAL', 'HES', 'KMI', 'MPC', 'MRO', 'OKE', 'OXY', \n",
    "         'PSX', 'PXD', 'SLB', 'TRGP', 'VLO', 'WMB', 'XOM', 'RRC', \n",
    "         'CNQ', 'ENB', 'SU', 'BP','RDS.A', 'RDS.B', 'TOT', 'E', \n",
    "         'EPD', 'MUR', 'NBL', 'NOV', 'OVV', 'PBR', 'PDCE', 'CNX', \n",
    "         'CLR', 'CHK', 'AR', 'CTRA', 'Do', 'EC', 'EQT', 'XEC', 'FRAC', \n",
    "         'GDP', 'HPK', 'LPI', 'MGY', 'MUR', 'NOG', 'OAS', 'OVV', 'PBR', \n",
    "         'PDCE', 'PE', 'PXD', 'QEP', 'REN', 'RIG', 'SDR', 'SWN', \n",
    "         'TALO', 'WTI', 'XEC', 'XOG', 'COG', 'CXO', 'DK', 'EC', \n",
    "         'EPM', 'FTI', 'HP', 'LNG', 'MMP', 'PAA', 'PBF', 'SM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0ff7e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PXD']: Exception('%ticker%: No data found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['RDS.A']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['RDS.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 1999-01-01 -> 2019-12-31)')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['TOT']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NBL']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PDCE']: Exception(\"%ticker%: Period 'max' is invalid, must be one of ['1d', '5d']\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['CLR']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['CHK']: Exception('%ticker%: No data found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['DO']: Exception('%ticker%: No data found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['XEC']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['FRAC']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GDP']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['LPI']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['OAS']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PDCE']: Exception(\"%ticker%: Period 'max' is invalid, must be one of ['1d', '5d']\")\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PE']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PXD']: Exception('%ticker%: No data found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['QEP']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['REN']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SDR']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SWN']: Exception('%ticker%: No data found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['XEC']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['XOG']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['COG']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['CXO']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MMP']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running strategy for cutoff: 2017-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  portfolio[f'Capital'].iloc[z+1] = capital\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates 2017-01-01 00:00:00 : 2017-07-01 00:00:00\n",
      "Running strategy for cutoff: 2017-07-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  portfolio[f'Capital'].iloc[z+1] = capital\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates 2017-07-01 00:00:00 : 2018-01-01 00:00:00\n",
      "Running strategy for cutoff: 2018-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  portfolio[f'Capital'].iloc[z+1] = capital\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates 2018-01-01 00:00:00 : 2018-07-01 00:00:00\n",
      "Running strategy for cutoff: 2018-07-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  portfolio[f'Capital'].iloc[z+1] = capital\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates 2018-07-01 00:00:00 : 2019-01-01 00:00:00\n",
      "Running strategy for cutoff: 2019-01-01 00:00:00\n",
      "Dates 2019-01-01 00:00:00 : 2019-07-01 00:00:00\n",
      "Running strategy for cutoff: 2019-07-01 00:00:00\n",
      "Dates 2019-07-01 00:00:00 : 2020-01-01 00:00:00\n",
      "All results:\n",
      "Cutoff: 2017-01-01 00:00:00, CAGR: 10.777%, Final Portfolio Value: 105117.99\n",
      "Cutoff: 2017-07-01 00:00:00, CAGR: 10.980%, Final Portfolio Value: 105241.93\n",
      "Cutoff: 2018-01-01 00:00:00, CAGR: 8.933%, Final Portfolio Value: 104260.99\n",
      "Cutoff: 2018-07-01 00:00:00, CAGR: 0.508%, Final Portfolio Value: 100252.93\n",
      "Cutoff: 2019-01-01 00:00:00, CAGR: 0.000%, Final Portfolio Value: 100000.00\n",
      "Cutoff: 2019-07-01 00:00:00, CAGR: 6.969%, Final Portfolio Value: 103416.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p1}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signals[f'{p2}S'].loc[zero_idx:] = 0\n",
      "C:\\Users\\tzs7ch\\AppData\\Local\\Temp\\ipykernel_21168\\2747149755.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  portfolio[f'Capital'].iloc[z+1] = capital\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "start_date = '1999-01-01'\n",
    "end_date = '2019-12-31'\n",
    "lookback1 = 2 #length of lookback for calculating z-score\n",
    "lookback2 = 1 #length of lookback for calculating mean and std of z-score\n",
    "lookback3 = 3 #training data length and lookback for OLS\n",
    "\n",
    "z_score_cutoff = 2 #stds above/below mean z-score needed to enter trade\n",
    "period = 6 #number of months between retraining/selection of new pairs\n",
    "\n",
    "cutoff_freq = f'{period}MS' \n",
    "cutoffs = pd.bdate_range(\"2017-01-01\", \"2019-12-01\", freq=cutoff_freq)\n",
    "\n",
    "#Make sure lookbacks are viable lengths\n",
    "check = cutoffs[0].year - pd.to_datetime(start_date).year\n",
    "if(lookback1>check or lookback2>check or lookback3>check/2):\n",
    "    sys.exit(\"Please change lookback periods\")\n",
    "    \n",
    "days_before_end = 5 #No trades within x days of end of period\n",
    "deg_freedom = .75 #freedom for trade to revert to mean (x * entry is exit position)\n",
    "\n",
    "cagrs, end_caps, end = run(start_date, end_date, cutoffs, period, lookback1, lookback2, lookback3, z_score_cutoff, days_before_end, deg_freedom, tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "351f3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105117.99429483642\n",
      "110628.2057929543\n",
      "115342.06295932188\n",
      "115633.79839558092\n",
      "115633.79839558092\n",
      "119584.26723194518\n",
      "End Capital (started with $100000) $ 119584.27\n",
      "Total CAGR:  6.1430%\n"
     ]
    }
   ],
   "source": [
    "start_cap = capital = 100000\n",
    "for cagr, final_value in zip(cagrs, end_caps):\n",
    "    capital = capital + ((final_value-start_cap)/start_cap)*capital\n",
    "    print(capital)\n",
    "print(f'End Capital (started with $100000) ${capital: .2f}')\n",
    "delta = (end - cutoffs[0]).days\n",
    "print(f'Total CAGR: {((capital/(start_cap)) ** (365/delta) - 1)*100: .4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedb2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
